{"cells":[{"metadata":{},"cell_type":"markdown","source":["# Predicting Molecular Properties\n","---\n","\n","The goal of this competition is to find a **coupling constant** through intermolecular bonding. Coupling Constant is constant indicating the strength of the physical interaction (here between atoms), called a complete combination when the combined constant is 1.\n","\n","We receive the coupling constant information from the *'train data'* by the coupling of two atoms. And from the *'Structures data'* we get the x, y, z axis information for each atom.  \n","\n","#### Training Strategy\n","For model training, I did not train the entire data, but I did the train by each **'type'** of molecular.\n","And I used the **LightGBM** for model training. "]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading champs-scalar-coupling.zip to c:\\Users\\YC\\Documents\\staging\\molecular\n","\n","\n","  0%|          | 0.00/377M [00:00<?, ?B/s]\n","  1%|          | 3.00M/377M [00:00<00:15, 25.4MB/s]\n","  2%|▏         | 6.00M/377M [00:00<00:15, 24.3MB/s]\n","  3%|▎         | 11.0M/377M [00:00<00:11, 33.8MB/s]\n","  5%|▍         | 17.0M/377M [00:00<00:13, 28.1MB/s]\n","  6%|▌         | 23.0M/377M [00:00<00:10, 35.4MB/s]\n","  7%|▋         | 27.0M/377M [00:01<00:17, 21.4MB/s]\n","  9%|▉         | 33.0M/377M [00:01<00:19, 18.6MB/s]\n"," 10%|█         | 39.0M/377M [00:01<00:14, 24.3MB/s]\n"," 11%|█▏        | 43.0M/377M [00:01<00:13, 25.3MB/s]\n"," 13%|█▎        | 49.0M/377M [00:01<00:10, 31.6MB/s]\n"," 15%|█▍        | 55.0M/377M [00:02<00:09, 37.1MB/s]\n"," 16%|█▌        | 60.0M/377M [00:02<00:08, 38.7MB/s]\n"," 18%|█▊        | 66.0M/377M [00:02<00:07, 43.9MB/s]\n"," 19%|█▉        | 72.0M/377M [00:02<00:06, 48.2MB/s]\n"," 21%|██        | 78.0M/377M [00:02<00:07, 43.3MB/s]\n"," 22%|██▏       | 84.0M/377M [00:02<00:06, 47.2MB/s]\n"," 24%|██▍       | 90.0M/377M [00:02<00:05, 50.1MB/s]\n"," 25%|██▌       | 96.0M/377M [00:02<00:05, 52.4MB/s]\n"," 27%|██▋       | 102M/377M [00:02<00:05, 54.6MB/s] \n"," 29%|██▊       | 108M/377M [00:03<00:05, 48.3MB/s]\n"," 30%|███       | 114M/377M [00:03<00:05, 51.3MB/s]\n"," 32%|███▏      | 120M/377M [00:03<00:05, 53.5MB/s]\n"," 33%|███▎      | 126M/377M [00:03<00:04, 55.5MB/s]\n"," 35%|███▌      | 132M/377M [00:03<00:04, 56.8MB/s]\n"," 37%|███▋      | 138M/377M [00:03<00:06, 40.3MB/s]\n"," 38%|███▊      | 144M/377M [00:03<00:05, 44.7MB/s]\n"," 40%|███▉      | 150M/377M [00:04<00:04, 48.6MB/s]\n"," 41%|████▏     | 156M/377M [00:04<00:11, 19.8MB/s]\n"," 43%|████▎     | 161M/377M [00:04<00:09, 23.5MB/s]\n"," 44%|████▍     | 166M/377M [00:04<00:08, 27.3MB/s]\n"," 45%|████▌     | 171M/377M [00:05<00:06, 31.3MB/s]\n"," 47%|████▋     | 176M/377M [00:05<00:07, 26.3MB/s]\n"," 48%|████▊     | 181M/377M [00:05<00:06, 30.1MB/s]\n"," 49%|████▉     | 186M/377M [00:05<00:05, 33.7MB/s]\n"," 51%|█████     | 191M/377M [00:05<00:05, 37.5MB/s]\n"," 52%|█████▏    | 197M/377M [00:05<00:04, 41.2MB/s]\n"," 54%|█████▎    | 202M/377M [00:05<00:04, 43.1MB/s]\n"," 55%|█████▍    | 207M/377M [00:06<00:04, 44.4MB/s]\n"," 57%|█████▋    | 213M/377M [00:06<00:03, 46.9MB/s]\n"," 58%|█████▊    | 219M/377M [00:06<00:03, 50.2MB/s]\n"," 60%|█████▉    | 225M/377M [00:06<00:03, 52.1MB/s]\n"," 62%|██████▏   | 232M/377M [00:06<00:02, 55.7MB/s]\n"," 63%|██████▎   | 238M/377M [00:06<00:02, 56.9MB/s]\n"," 65%|██████▍   | 244M/377M [00:06<00:02, 57.7MB/s]\n"," 66%|██████▋   | 250M/377M [00:07<00:04, 28.3MB/s]\n"," 68%|██████▊   | 255M/377M [00:07<00:03, 32.0MB/s]\n"," 69%|██████▉   | 260M/377M [00:07<00:03, 35.7MB/s]\n"," 70%|███████   | 265M/377M [00:07<00:03, 35.8MB/s]\n"," 72%|███████▏  | 271M/377M [00:07<00:02, 40.0MB/s]\n"," 74%|███████▎  | 277M/377M [00:07<00:02, 44.4MB/s]\n"," 75%|███████▍  | 282M/377M [00:07<00:02, 44.8MB/s]\n"," 76%|███████▋  | 288M/377M [00:07<00:01, 48.1MB/s]\n"," 78%|███████▊  | 294M/377M [00:08<00:01, 50.5MB/s]\n"," 80%|███████▉  | 300M/377M [00:08<00:01, 52.4MB/s]\n"," 81%|████████  | 306M/377M [00:08<00:01, 52.3MB/s]\n"," 83%|████████▎ | 312M/377M [00:08<00:01, 54.1MB/s]\n"," 84%|████████▍ | 318M/377M [00:08<00:01, 55.9MB/s]\n"," 86%|████████▌ | 324M/377M [00:08<00:00, 57.1MB/s]\n"," 88%|████████▊ | 330M/377M [00:08<00:01, 45.6MB/s]\n"," 89%|████████▉ | 336M/377M [00:08<00:00, 49.2MB/s]\n"," 91%|█████████ | 342M/377M [00:09<00:00, 51.7MB/s]\n"," 92%|█████████▏| 348M/377M [00:09<00:00, 54.0MB/s]\n"," 94%|█████████▍| 354M/377M [00:09<00:00, 55.7MB/s]\n"," 96%|█████████▌| 360M/377M [00:09<00:00, 56.9MB/s]\n"," 97%|█████████▋| 366M/377M [00:09<00:00, 57.8MB/s]\n"," 99%|█████████▊| 372M/377M [00:09<00:00, 57.2MB/s]\n","100%|██████████| 377M/377M [00:09<00:00, 40.9MB/s]\n"]}],"source":["!kaggle competitions download -c champs-scalar-coupling"]},{"metadata":{"trusted":true},"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import os\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.mplot3d import Axes3D\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","import lightgbm as lgb\n","\n","# path\n","path_dir = '../input/champs-scalar-coupling/'\n","file_list = os.listdir(path_dir)\n","file_list"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 1. Load Train/Test Data\n","**Columns**\n","- molecule_name\n","- atom_index_0 / atom_index_1\n","- type\n","- Coupling Constant : A constant indicating the strength of the physical interaction (here between atoms), called a complete combination when the combined constant is 1."]},{"metadata":{"trusted":true},"cell_type":"code","source":["train_df = pd.read_csv(path_dir+'train.csv')\n","test_df = pd.read_csv(path_dir+'test.csv')   # target = 'scalar_coupling_constant'\n","\n","print('Length of train set: {}'.format(len(train_df)))\n","print('Length of test set: {}'.format(len(test_df)))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["print('Unique molecule of train set: {}'.format(len(train_df['molecule_name'].unique())))\n","train_df.head()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["print('Unique molecule of test set: {}'.format(len(test_df['molecule_name'].unique())))\n","test_df.head()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 2. EDA"]},{"metadata":{},"cell_type":"markdown","source":["#### 2.1 Distribution of Target ('scalar_coupling_constant')\n","- Min Value : -36.2186\n","- Max Value : 204.88\n","- Most are between -20 and +20\n","- Small distribution exists between 80 and 100"]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Distribution of target\n","print('Min Value of Target : {}'.format(train_df['scalar_coupling_constant'].min()))\n","print('Max Value of Target : {}'.format(train_df['scalar_coupling_constant'].max()))\n","\n","plt.figure(figsize=(11, 5))\n","sns.distplot(train_df['scalar_coupling_constant'])\n","plt.title('Distribution of scalar_coupling_constant')\n","plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["#### 2.2 Distribution of 'scalar_coupling_constant' by type\n","- '1JHC' type is distributed in a relatively high scalar coupling range(+66.6 ~ +204.8) \n","- '2JHH' type is distributed in a relatively low scalar coupling range(-35.1 ~ +11.8"]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Distribution of 'scalar_coupling_constant' by type\n","plt.figure(figsize=(14, 13))\n","for i, t in enumerate(train_df['type'].unique()):\n","    plt.subplot(4,2, i+1)\n","    sns.distplot(train_df[train_df['type'] == t]['scalar_coupling_constant'])\n","    plt.title('Distribution of coupling constant by type '+ t)\n","    plt.tight_layout()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["#### 2.3 Count by 'type'\n","- High in order 3JHC, 2JHC, 1JHC, 3JHH, 2JHH, 3JHN, 2JHN, 1JHN."]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Count by 'type'\n","type_index = train_df['type'].value_counts().index\n","type_cnt = train_df['type'].value_counts()\n","\n","plt.figure(figsize=(11, 4))\n","sns.barplot(x=type_index, y=type_cnt)\n","plt.xlabel('type'); plt.ylabel('Count')\n","plt.title('Count by type')\n","plt.tight_layout()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["#### 2.4 Count by atom index 0, 1\n","- Atom index 0 has the most number of distributions from 9 to 18.\n","- Atom index 1 has the most number of distributions from 1 to 8."]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Count by atom index 0, 1\n","for i in [0, 1]:\n","    atom_index = train_df['atom_index_'+str(i)].value_counts().index\n","    atom_cnt = train_df['atom_index_'+str(i)].value_counts()\n","    \n","    plt.figure(figsize=(11, 4))\n","    sns.barplot(x=atom_index, y=atom_cnt)\n","    plt.xlabel('atom index '+str(i)); plt.ylabel('Count')\n","    plt.title('Count by atom index '+str(i))\n","    plt.tight_layout()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 3. Load Structures Data\n","**Columns**\n","- molecule_name\n","- atom_index\n","- atom\n","- x, y, z axis of atom"]},{"metadata":{"trusted":true},"cell_type":"code","source":["structures_df = pd.read_csv(path_dir+'structures.csv')\n","\n","print('Length of test set: {}'.format(len(structures_df)))\n","structures_df.head()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["#### 3.1. 3Dimension plot by Molecule"]},{"metadata":{"trusted":true},"cell_type":"code","source":["for name in structures_df['molecule_name'].unique()[:4]:\n","    structures_molecule =structures_df[structures_df['molecule_name'] == name]\n","\n","    fig = plt.figure(figsize=(8, 5))\n","    ax = fig.add_subplot(111, projection='3d')\n","    ax.scatter(structures_molecule['x'], structures_molecule['y'], structures_molecule['z'], s=200, edgecolors='white')\n","    ax.set_title(str(name)+ ' 3D plot')\n","    ax.set_xlabel('x')\n","    ax.set_ylabel('y')\n","    ax.set_zlabel('z')\n","    plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 4. Preprocessing\n","#### 4.1. Merge Train&Test - Structures Data"]},{"metadata":{"trusted":true},"cell_type":"code","source":["def mapping_atom_index(df, atom_idx):\n","    atom_idx = str(atom_idx)\n","    df = pd.merge(df, structures_df,\n","                  left_on  = ['molecule_name', 'atom_index_'+atom_idx],\n","                  right_on = ['molecule_name',  'atom_index'],\n","                 how = 'left')\n","    \n","    df = df.drop('atom_index', axis=1)\n","    df = df.rename(columns={'atom': 'atom_'+atom_idx,\n","                            'x': 'x_'+atom_idx,\n","                            'y': 'y_'+atom_idx,\n","                            'z': 'z_'+atom_idx})\n","    return df"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["train_merge = mapping_atom_index(train_df, 0)\n","train_merge = mapping_atom_index(train_merge, 1)\n","\n","test_merge = mapping_atom_index(test_df, 0)\n","test_merge = mapping_atom_index(test_merge, 1)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["train_tmp = train_merge[['id','molecule_name','type']]\n","test_tmp = test_merge[['id','molecule_name','type']]\n","\n","train_merge.head()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["#### 4.2. Derived variables - 'Distance'\n","- distance between *x axis* of atom index\n","- distance between *y axis* of atom index\n","- distance between *z axis* of atom index\n","- distance between *atom*"]},{"metadata":{"trusted":true},"cell_type":"code","source":["def dist_between_atom(df):\n","    # distance between axis of atom\n","    df['x_dist'] = (df['x_0'] - df['x_1'])**2\n","    df['y_dist'] = (df['y_0'] - df['y_1'])**2\n","    df['z_dist'] = (df['z_0'] - df['z_1'])**2\n","    \n","    # distance between atom\n","    df['atom_dist'] = (df['x_dist']+df['y_dist']+df['z_dist'])**0.5\n","    \n","    return df\n","    \n","train_dist = dist_between_atom(train_merge)\n","test_dist = dist_between_atom(test_merge)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["train_dist.head()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["#### 4.3. Label encoding \n","- type, atom_0, atom_1"]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Label encoding\n","categorical_features = ['type', 'atom_0', 'atom_1']\n","for col in categorical_features:\n","    le = LabelEncoder()\n","    le.fit(list(train_dist[col].values) + list(test_dist[col].values))\n","    train_dist[col] = le.transform(list(train_dist[col].values))\n","    test_dist[col] = le.transform(list(test_dist[col].values))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["train_le = train_dist.copy()\n","test_le = test_dist.copy()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["train_le.head()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["#### 4.4. Standardization\n","- z = (x - u) / s"]},{"metadata":{"trusted":true},"cell_type":"code","source":["# train\n","train_data = train_le.drop(['id','molecule_name','scalar_coupling_constant'], axis=1)\n","train_target = train_le['scalar_coupling_constant']\n","# test\n","test_data = test_le.drop(['id','molecule_name',], axis=1)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# z-score standardization\n","train_scale = (train_data - train_data.mean()) / train_data.mean()\n","train_scale = train_scale.fillna(0)\n","test_scale = (test_data - train_data.mean()) / train_data.mean()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["#### 4.5. Variable Correlations"]},{"metadata":{"trusted":true},"cell_type":"code","source":["train_corr = train_scale.copy()\n","train_corr['scalar_coupling_constant'] = train_target\n","corrmat = train_corr.corr()\n","top_corr_features = corrmat.index[abs(corrmat['scalar_coupling_constant']) >= 0.1]\n","\n","plt.figure(figsize=(10,7))\n","sns.heatmap(train_corr[top_corr_features].corr(), annot=True, cmap=\"RdYlGn\")\n","plt.title('Variable Correlations')\n","plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 5. Training by LightGBM "]},{"metadata":{},"cell_type":"markdown","source":["#### 5.1. Training by 'type' through LightGBM"]},{"metadata":{"trusted":true},"cell_type":"code","source":["train_scale = train_scale.drop('type', axis=1)\n","train_scale['type'] = train_tmp['type']\n","train_scale['scalar_coupling_constant'] = train_target\n","\n","test_scale = test_scale.drop('type', axis=1)\n","test_scale[['id', 'type']] = test_tmp[['id', 'type']]"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["score_by_type = []    # List of Validation score by type \n","feature_importance_df = []\n","test_pred_df = pd.DataFrame(columns=['id', 'scalar_coupling_constant'])   # Dataframe for submission\n","\n","# Extract data by type\n","types = train_tmp['type'].unique()\n","for typ in types:\n","    print('---Type of '+str(typ)+'---')\n","    \n","    train = train_scale[train_scale['type'] == typ]\n","    target = train['scalar_coupling_constant']\n","    train = train.drop(['type','scalar_coupling_constant'], axis=1)\n","    \n","    # Split train set / valid set\n","    x_train, x_val, y_train, y_val = train_test_split(train, target, random_state=42)\n","    \n","    # LightGBM\n","    categorical_features = ['atom_0','atom_1']\n","    lgb_train = lgb.Dataset(x_train, y_train, categorical_feature=categorical_features)\n","    lgb_val = lgb.Dataset(x_val, y_val, categorical_feature=categorical_features)\n","\n","    # Parameters of LightGBM\n","    params = {'num_leaves': 128,\n","              'min_child_samples': 79,\n","              'objective': 'regression',\n","              'max_depth': 9,\n","              'learning_rate': 0.1,\n","              \"boosting_type\": \"gbdt\",\n","              \"subsample_freq\": 1,\n","              \"subsample\": 0.9,\n","              \"bagging_seed\": 11,\n","              \"metric\": 'mae',\n","              \"verbosity\": -1,\n","              'reg_alpha': 0.13,\n","              'reg_lambda': 0.36,\n","              'colsample_bytree': 1.0\n","             }\n","    # Training\n","    lgb_model = lgb.train(params, lgb_train, valid_sets=[lgb_train, lgb_val], \n","                          num_boost_round=15000,    # Number of boosting iterations.\n","                          early_stopping_rounds=500,    # early stopping for valid set\n","                          verbose_eval=2500)    # eval metric on the valid set is printed at 2500 each boosting\n","    \n","    # Feature Importances\n","    feature_importance = lgb_model.feature_importance()\n","    df_fi = pd.DataFrame({'columns':x_train.columns, 'importances':feature_importance})\n","    df_fi = df_fi[df_fi['importances'] > 0].sort_values(by=['importances'], ascending=False)\n","    feature_importance_df.append(df_fi)\n","    \n","    # Predict Validation set\n","    score_by_type.append(list(lgb_model.best_score['valid_1'].values()))\n","    \n","    # Predict Test set\n","    test = test_scale[test_scale['type'] == typ]\n","    test_id = test['id']\n","    test = test.drop(['id','type'], axis=1)\n","    \n","    test_preds = lgb_model.predict(test)\n","    test_pred_df = pd.concat([test_pred_df, pd.DataFrame({'id':test_id, 'scalar_coupling_constant':test_preds})], axis=0)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["#### 5.2. Validation MAE by type"]},{"metadata":{"trusted":true},"cell_type":"code","source":["for typ, score in zip(types, score_by_type):\n","    print('Type {} valid MAE  : {}'.format(str(typ), score))\n","\n","print('\\nAverage of valid MAE  : {}'.format(np.mean(score_by_type)))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["#### 5.3. Feature Importances Plot by Type"]},{"metadata":{"trusted":true},"cell_type":"code","source":["for typ, df_fi in zip(types, feature_importance_df):\n","    fig = plt.figure(figsize=(12, 6))\n","    ax = sns.barplot(df_fi['columns'], df_fi['importances'])\n","    ax.set_xticklabels(df_fi['columns'], rotation=80, fontsize=13)\n","    plt.title('Type '+str(typ)+' feature importance')\n","    plt.tight_layout()\n","    plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["#### 5.4. Save prediction of test set to *.csv "]},{"metadata":{"trusted":true},"cell_type":"code","source":["test_pred_df.head(10)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["test_pred_df.to_csv('lgb_submission.csv', index=False)"],"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.7.3 32-bit","metadata":{"interpreter":{"hash":"176ed7074dac5392121fe20cc63b8a25e8cf34c6f1ec6a1ab2217b716782b9b2"}}},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3-final"}},"nbformat":4,"nbformat_minor":1}