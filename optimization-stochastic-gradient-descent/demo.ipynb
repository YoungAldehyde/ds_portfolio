{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic optimization #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will show step-by-step mathematical derivation for the gradient of the cost function $\\ell(\\theta)$ ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In logistic regression model,\n",
    "### $p(y=1|x,\\theta) = \\frac{1}{1+exp(-\\theta^Tx)}$ and $p(y=0|x,\\theta) = 1 -\\frac{1}{1+exp(-\\theta^Tx)} = \\frac{exp(-\\theta^Tx))}{1+exp(-\\theta^Tx)}$ ###\n",
    "### Plugging these into a log likelihood function, $\\ell(\\theta): = log \\prod_{i=1}^mP(y^i|x^i,\\theta)$ ###\n",
    "### $\\ell(\\theta) = \\Sigma_{i=1}^Ny_ilog(p(x_i;\\theta)+(1-y_i)log(1-p(x_i;\\theta)))$ (multiplication becomes a sum) ###\n",
    "### $=\\Sigma_{i=1}^Ny_ilog(\\frac{1}{1+exp(-\\theta^Tx_i)})+(1-y_i)log(1-\\frac{1}{1+exp(-\\theta^Tx_i)})$ ###\n",
    "### $=\\Sigma_{i=1}^Ny_i(-1)(1+exp(-\\theta^Tx_i))+(1-y_i)log(\\frac{exp(-\\theta^Tx_i)}{1+exp(-\\theta^Tx_i)})$ ###\n",
    "### $=\\Sigma_{i=1}^N-y_i(1+exp(-\\theta^Tx_i))+(1-y_i)[log(exp(-\\theta^Tx_i))-log(1+exp(-\\theta^Tx_i))]$ (log of a quotient is the difference of the logs) ###\n",
    "### $=\\Sigma_{i=1}^N-y_i(1+exp(-\\theta^Tx_i))+(1-y_i)[(-\\theta^Tx_i)-log(1+exp(-\\theta^Tx_i))]$ (log of expoent cancelling to 1) ###\n",
    "### $=\\Sigma_{i=1}^N(y_i-1)\\theta^Tx_i-log(1+exp(-\\theta^Tx_i))$ ###\n",
    "### This is the log-likelihood objective function we want to maximize. In order to find to maximizer, we need to satisfy the first order condition, which means this gradient needs to be zero at the maximizer. ### \n",
    "### Next, calculate the derivative of the log likelihood with respect to each $\\theta$ ###\n",
    "### $\\frac{\\partial}{\\partial z}\\sigma(z) = \\sigma(z)[1-\\sigma(z)]$ ###\n",
    "### Since $\\sigma(\\theta^Tx) = \\frac{1}{1+exp(-\\theta^Tx)}$ ###\n",
    "### $\\frac{d}{d\\theta}\\sigma(\\theta^Tx)=\\frac{exp(-\\theta x)x}{1+exp(-\\theta^Tx)^2} = exp(-\\theta^Tx)x[\\sigma(\\theta^Tx)]^2$ ###\n",
    "### $=(1+exp(-\\theta^Tx)-1)x[\\sigma(\\theta^Tx)]^2$ ###\n",
    "### $=(\\frac{1}{\\sigma(\\theta^Tx)}-1)x[\\sigma(\\theta^Tx)]^2$ ###\n",
    "### $=([\\sigma(\\theta^Tx)]-[\\sigma(\\theta^Tx)]^2)x$ ###\n",
    "### $=[\\sigma(\\theta^Tx)][1-[\\sigma(\\theta^Tx)]x$ ###\n",
    "### Derivative of at log of one point, $\\frac{\\partial}{\\partial\\theta}ylog\\sigma(\\theta^Tx)+\\frac{\\partial}{\\partial\\theta}(1-y)log[1-\\sigma(\\theta^Tx)]$ ### \n",
    "### $=[\\frac{y}{\\sigma(\\theta^Tx)}-\\frac{1-y}{1-\\sigma(\\theta^Tx)}]\\frac{\\partial}{\\partial\\theta}\\sigma(\\theta^Tx)$ ###\n",
    "### $=[\\frac{y}{\\sigma(\\theta^Tx)}-\\frac{1-y}{1-\\sigma(\\theta^Tx)}]\\sigma(\\theta^Tx)[1-\\sigma(\\theta^Tx)]x$ ###\n",
    "### $=[\\frac{y-\\sigma(\\theta^Tx)}{\\sigma(\\theta^Tx)[1-\\sigma(\\theta^Tx)]}]\\sigma(\\theta^Tx)[1-\\sigma(\\theta^Tx)]x$ ###\n",
    "### $=[y-\\sigma(\\theta^Tx)]x$ ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. In gradient descent, we first initialize parameter $\\theta^0$, and learning rate $\\gamma_t$ ###\n",
    "### 2. Then calculate $\\frac{\\partial}{\\partial\\theta}\\ell(\\theta)$ at $t^{th}$ instance ###\n",
    "### 3. Next multiply the result from above by learning rate $\\gamma_t$ and subtract this from the previous $\\theta^t$ ###\n",
    "### 4. Repeat 2~3 until $|| \\theta^{t+1} - \\theta^{t} || > \\epsilon $\n",
    "### 5. Return the final weights ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. At each iteration of stochastic gradient descent, random sample n without replacement a subset $S_t$ data point $(x_i,y_i), i \\in S_t$  ###\n",
    "\n",
    "### 2. Then calculate $\\frac{\\partial}{\\partial\\theta}\\ell(\\theta)$ at $t^{th}$ instance ### \n",
    "\n",
    "### 3. Next update $\\theta^t$ by multiplying the result from above by $\\gamma_t$ and subtracting it from the previous $\\theta^t-1$ ###\n",
    "\n",
    "### 4. In the next iteration with a decreased step size such as $O(\\frac{1}{t})$ random sample from another $S_t$\n",
    "\n",
    "### 4. Repeat 1~4 until $|| \\theta^{t+1} - \\theta^{t} || > \\epsilon $\n",
    "\n",
    "### 5. Return the final weights ###\n",
    "\n",
    "### The difference of SGD vs. GD is that in SGD, before looping, need to random shuffle the training data. This is an intended behavior because this prevents us from calculating a dot product over entire training data to move a single step. However, SGD is much faster and gauranteed to perform as good as GD given the right step size. ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d  We will show that the training problem in basic logistic regression problem is concave. Derive the Hessian matrix of $\\ell(\\theta)$ and based on this, show the training problem (1) is concave (note that in this case, since we only have one feature, the Hessian matrix is just a scalar). This problem can be solved efficiently and gradient descent will achieve a unique global optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Hessian\\:\\ell(\\theta) = \n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial^2\\ell(\\theta)}{\\partial\\theta_1^2} \\\\\n",
    "\\frac{\\partial^2\\ell(\\theta)}{\\partial\\theta_2\\partial\\theta_1} \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{\\partial^2\\ell(\\theta)}{\\partial\\theta_n\\partial\\theta_1} \n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting with gradient of the likelihood function, $\\frac{\\partial\\ell(\\theta)}{\\partial(\\theta)}=\\Sigma_i(y_i-1)x_i+\\frac{exp(-\\theta^T x_i)x_i}{1+exp(-\\theta^T x_i)}$ ###\n",
    "### $(y_i-1)x_i$ term drops because it is a derivative w.r.t. $\\theta$ ###\n",
    "### Using a quotient rule & chain rule ###\n",
    "### $=\\frac{(exp(-\\theta^T x_i)x_i)'(exp(-\\theta^T x_i)) - exp(-\\theta^T x_i)x_i(exp(-\\theta^T x_i))'}{[exp(-\\theta^T x_i)]^2}$ ###\n",
    "### $=\\frac{(exp(-\\theta^T x_i)x_i)(exp(-\\theta^T x_i)) - exp(-\\theta^T x_i)x_i(exp(-\\theta^T x_i))}{[exp(-\\theta^T x_i)]^2}$ ###\n",
    "### $= -\\dfrac{x_i\\theta\\mathrm{e}^{-x_i\\theta}}{\\mathrm{e}^{-x_i\\theta}+1}+\\dfrac{\\mathrm{e}^{-x_i\\theta}}{\\mathrm{e}^{-x_i\\theta}+1}+\\dfrac{x_i\\theta\\mathrm{e}^{-2x_i\\theta}}{\\left(\\mathrm{e}^{-x_i\\theta}+1\\right)^2}$ ###\n",
    "### Because the Hessian matrix represents the 2nd derivatives, this being negative means 1st order derivative is decreasing, thus in the concave downwards interval. This works well with Gradient Descent/Ascent approach because the updated weights will decrease after each iteration ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________________________________________________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}