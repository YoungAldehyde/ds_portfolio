{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class classification for MNIST data set #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST database of handwritten digits has a training set of 60,000 examples, and a test set of 10,000 examples. We will compare KNN, logistic regression, SVM, kernel SVM, and neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "filename=\".\\\\mnist_10digits.mat\"\n",
    "digits = loadmat(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file Platform: posix, Created on: Tue Oct 13 20:00:03 2020',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'xtrain': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " 'ytrain': array([[5, 0, 4, ..., 5, 6, 8]], dtype=int64),\n",
       " 'xtest': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " 'ytest': array([[7, 2, 1, ..., 4, 5, 6]], dtype=int64)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "(1, 60000)\n",
      "(1, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(digits['xtrain'].shape)\n",
    "print(digits['xtest'].shape)\n",
    "print(digits['ytrain'].shape)\n",
    "print(digits['ytest'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = digits['xtrain']\n",
    "X_test = digits['xtest']\n",
    "y_train = digits['ytrain'].T.ravel()\n",
    "y_test = digits['ytest'].T.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standarize the features\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here I am random sampling 5000 images from the training sets for quick computations ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "X_train_sample, y_train_sample = resample(X_train, y_train, n_samples = 5000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import sklearn.svm as svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic_Regression \n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      "[[ 957    0    1    4    0    4    6    2    4    2]\n",
      " [   1 1108    4    1    0    4    4    2   11    0]\n",
      " [   9    9  883   27   12    6   15   15   48    8]\n",
      " [   7    2   22  889    0   33    3   12   28   14]\n",
      " [   2    4   12    2  903    0    6    1   10   42]\n",
      " [  13    5    6   42   16  731   23    8   38   10]\n",
      " [  14    2   10    1    7   19  899    2    4    0]\n",
      " [   3   10   21    6   12    2    0  928    7   39]\n",
      " [  13   13   14   34   12   35   18    7  821    7]\n",
      " [  13    7    5    8   54    9    0   18   20  875]] \n",
      "\n",
      "Precision, Recall, and F-1 score: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95       980\n",
      "           1       0.96      0.98      0.97      1135\n",
      "           2       0.90      0.86      0.88      1032\n",
      "           3       0.88      0.88      0.88      1010\n",
      "           4       0.89      0.92      0.90       982\n",
      "           5       0.87      0.82      0.84       892\n",
      "           6       0.92      0.94      0.93       958\n",
      "           7       0.93      0.90      0.92      1028\n",
      "           8       0.83      0.84      0.84       974\n",
      "           9       0.88      0.87      0.87      1009\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#LR\n",
    "method_name = 'Logistic_Regression'\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "cm = metrics.confusion_matrix(y_true=y_test, \n",
    "                         y_pred = predictions, \n",
    "                        labels = clf.classes_)\n",
    "\n",
    "cr = metrics.classification_report(y_true=y_test, \n",
    "                         y_pred = predictions, \n",
    "                        labels = clf.classes_)\n",
    "\n",
    "print(method_name,'\\n')\n",
    "print('Confusion matrix: \\n')\n",
    "print(cm,'\\n')\n",
    "\n",
    "print('Precision, Recall, and F-1 score: \\n')\n",
    "print(cr,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN \n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      "[[ 969    1    1    0    1    2    5    1    0    0]\n",
      " [   0 1129    1    3    0    0    2    0    0    0]\n",
      " [  27   68  873    8    4    2    7   33    9    1]\n",
      " [   1    9    3  945    0   20    1   10   15    6]\n",
      " [   3   24    1    0  903    0    9    2    1   39]\n",
      " [   7   11    0   30    7  807   14    3    2   11]\n",
      " [  13    8    0    0    4    3  930    0    0    0]\n",
      " [   0   51    4    0    5    0    0  944    0   24]\n",
      " [  19   15    2   31   14   21    9    8  834   21]\n",
      " [   9   11    2    7   17    2    1   25    1  934]] \n",
      "\n",
      "Precision, Recall, and F-1 score: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96       980\n",
      "           1       0.85      0.99      0.92      1135\n",
      "           2       0.98      0.85      0.91      1032\n",
      "           3       0.92      0.94      0.93      1010\n",
      "           4       0.95      0.92      0.93       982\n",
      "           5       0.94      0.90      0.92       892\n",
      "           6       0.95      0.97      0.96       958\n",
      "           7       0.92      0.92      0.92      1028\n",
      "           8       0.97      0.86      0.91       974\n",
      "           9       0.90      0.93      0.91      1009\n",
      "\n",
      "    accuracy                           0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "method_name = 'KNN'\n",
    "clf = KNeighborsClassifier(10)\n",
    "clf.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "cm = metrics.confusion_matrix(y_true=y_test, \n",
    "                         y_pred = predictions, \n",
    "                        labels = clf.classes_)\n",
    "\n",
    "cr = metrics.classification_report(y_true=y_test, \n",
    "                         y_pred = predictions, \n",
    "                        labels = clf.classes_)\n",
    "\n",
    "print(method_name,'\\n')\n",
    "print('Confusion matrix: \\n')\n",
    "print(cm,'\\n')\n",
    "\n",
    "print('Precision, Recall, and F-1 score: \\n')\n",
    "print(cr,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear_SVM \n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      "[[ 957    0    3    2    0    9    8    1    0    0]\n",
      " [   0 1123    3    2    1    2    3    0    1    0]\n",
      " [  12    5  948   20   10    1   11    7   16    2]\n",
      " [  11    2   24  894    0   28    1   11   25   14]\n",
      " [   2    2    6    1  928    2    4    8    2   27]\n",
      " [  14    6   13   44   13  760   12    1   22    7]\n",
      " [  18    2   16    2    6   15  899    0    0    0]\n",
      " [   2   13   21    5    8    1    0  939    8   31]\n",
      " [  11   17   23   50   14   30   15    7  799    8]\n",
      " [  10    6   10   15   60    4    0   21    8  875]] \n",
      "\n",
      "Precision, Recall, and F-1 score: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95       980\n",
      "           1       0.95      0.99      0.97      1135\n",
      "           2       0.89      0.92      0.90      1032\n",
      "           3       0.86      0.89      0.87      1010\n",
      "           4       0.89      0.95      0.92       982\n",
      "           5       0.89      0.85      0.87       892\n",
      "           6       0.94      0.94      0.94       958\n",
      "           7       0.94      0.91      0.93      1028\n",
      "           8       0.91      0.82      0.86       974\n",
      "           9       0.91      0.87      0.89      1009\n",
      "\n",
      "    accuracy                           0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Linear SVM\n",
    "method_name = 'Linear_SVM'\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "cm = metrics.confusion_matrix(y_true=y_test, \n",
    "                         y_pred = predictions, \n",
    "                        labels = clf.classes_)\n",
    "\n",
    "cr = metrics.classification_report(y_true=y_test, \n",
    "                         y_pred = predictions, \n",
    "                        labels = clf.classes_)\n",
    "\n",
    "print(method_name,'\\n')\n",
    "print('Confusion matrix: \\n')\n",
    "print(cm,'\\n')\n",
    "\n",
    "print('Precision, Recall, and F-1 score: \\n')\n",
    "print(cr,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernal_SVM \n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      "[[ 966    0    4    0    0    2    4    1    3    0]\n",
      " [   0 1116    6    4    0    1    3    0    4    1]\n",
      " [   7    0  984    5    6    0    2    8   20    0]\n",
      " [   0    0   14  953    0   15    0    8   16    4]\n",
      " [   1    0    6    0  949    0    8    0    3   15]\n",
      " [   3    0    8   18    1  847    7    1    5    2]\n",
      " [   7    1    8    0    4   11  926    0    1    0]\n",
      " [   1    7   25    0    6    0    0  967    4   18]\n",
      " [   4    0   15   15    5    7    3    4  917    4]\n",
      " [   8    6   16    8   27    5    0    6    9  924]] \n",
      "\n",
      "Precision, Recall, and F-1 score: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       980\n",
      "           1       0.99      0.98      0.99      1135\n",
      "           2       0.91      0.95      0.93      1032\n",
      "           3       0.95      0.94      0.95      1010\n",
      "           4       0.95      0.97      0.96       982\n",
      "           5       0.95      0.95      0.95       892\n",
      "           6       0.97      0.97      0.97       958\n",
      "           7       0.97      0.94      0.96      1028\n",
      "           8       0.93      0.94      0.94       974\n",
      "           9       0.95      0.92      0.93      1009\n",
      "\n",
      "    accuracy                           0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.96      0.95      0.95     10000\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Kernal SVM\n",
    "method_name = 'Kernal_SVM'\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "#reduce the training set for the median trick\n",
    "X_train_sample_kernal_svm_median_trick, y_train_sample_kernal_svm_median_trick = resample(X_train_sample, y_train_sample, n_samples = 1000, random_state=0)\n",
    "\n",
    "#Median trick to find a good gamma\n",
    "training_distances = euclidean_distances(X_train_sample_kernal_svm_median_trick,X_train_sample_kernal_svm_median_trick) #compute pair-wise euclidean distances of reduced training sample (1000)\n",
    "M = np.median(training_distances) #compute median of the distances\n",
    "sigma = np.sqrt(M/2)\n",
    "gamma = 1/(np.power((2*sigma),2))\n",
    "\n",
    "clf = svm.SVC(kernel='rbf',\n",
    "             C = 1.0, \n",
    "             gamma = gamma)\n",
    "\n",
    "clf.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "cm = metrics.confusion_matrix(y_true=y_test, \n",
    "                         y_pred = predictions, \n",
    "                        labels = clf.classes_)\n",
    "\n",
    "cr = metrics.classification_report(y_true=y_test, \n",
    "                         y_pred = predictions, \n",
    "                        labels = clf.classes_)\n",
    "\n",
    "print(method_name,'\\n')\n",
    "print('Confusion matrix: \\n')\n",
    "print(cm,'\\n')\n",
    "\n",
    "print('Precision, Recall, and F-1 score: \\n')\n",
    "print(cr,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural_Net \n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      "[[ 948    0    8    1    3    8    5    2    3    2]\n",
      " [   0 1115    3    4    1    1    4    3    4    0]\n",
      " [   7    5  933   23    9    2   13   17   20    3]\n",
      " [   2    4   15  902    3   18    4   15   26   21]\n",
      " [   3    0   12    0  912    1    9    8    6   31]\n",
      " [   8    4    2   36   15  773   14    4   26   10]\n",
      " [  10    4   10    0   18   22  889    0    5    0]\n",
      " [   5    5   18    9    8    1    0  949   12   21]\n",
      " [   5    6    8   21    9   23   14    8  871    9]\n",
      " [   9    8    7    5   57   12    0   23   19  869]] \n",
      "\n",
      "Precision, Recall, and F-1 score: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       980\n",
      "           1       0.97      0.98      0.98      1135\n",
      "           2       0.92      0.90      0.91      1032\n",
      "           3       0.90      0.89      0.90      1010\n",
      "           4       0.88      0.93      0.90       982\n",
      "           5       0.90      0.87      0.88       892\n",
      "           6       0.93      0.93      0.93       958\n",
      "           7       0.92      0.92      0.92      1028\n",
      "           8       0.88      0.89      0.89       974\n",
      "           9       0.90      0.86      0.88      1009\n",
      "\n",
      "    accuracy                           0.92     10000\n",
      "   macro avg       0.92      0.91      0.91     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NN\n",
    "method_name = 'Neural_Nets'\n",
    "clf = MLPClassifier(alpha=0.1, max_iter=1000, hidden_layer_sizes = (20, 10))\n",
    "clf.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "cm = metrics.confusion_matrix(y_true=y_test, \n",
    "                         y_pred = predictions, \n",
    "                        labels = clf.classes_)\n",
    "\n",
    "cr = metrics.classification_report(y_true=y_test, \n",
    "                         y_pred = predictions, \n",
    "                        labels = clf.classes_)\n",
    "\n",
    "print(method_name,'\\n')\n",
    "print('Confusion matrix: \\n')\n",
    "print(cm,'\\n')\n",
    "\n",
    "print('Precision, Recall, and F-1 score: \\n')\n",
    "print(cr,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like kernal SVM performed the best on test data. My initial expectation was that Neural Nets would perform the best, but it didn't. And I think this could be improved by hyper-parameter tuning or using something like grid-search to find optimal values to maximize the performance.\n",
    "\n",
    "The fact that kernal SVM performed really well makese sense. Becasue compared to the linear version, rbf kernal lets the algorithm to draw a much more flexible decision boundaries involving curves (aka less linearly separable), it would perform very well with a task like digit recognitions, but obviously this cannot be used to make a general statement that kernal SVM always performs better than other algorithms, and the results will vary from dataset to dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}